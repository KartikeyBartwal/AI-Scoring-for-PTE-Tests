{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2fe6be-f642-4af9-826c-5bfdd2b635e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\maste\\anaconda3\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maste\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\maste\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\maste\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\maste\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "   ---------------------------------------- 0.0/260.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 153.6/260.1 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 260.1/260.1 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB ? eta 0:00:00\n",
      "Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 184.7/184.7 kB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, audioread, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2.post1 pooch-1.8.2 soxr-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47698f5a-5b3d-45e5-ab57-44b261ae9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/wav2vec2-conformer-rel-pos-large\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad1a5b8-547b-4287-a296-9ff1bfb59e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 6220-5780\n",
      "\n",
      " Directory of D:\\Freelancing\\AI Feature Scoring\\training data\n",
      "\n",
      "29-06-2024  16:28    <DIR>          .\n",
      "29-06-2024  16:28    <DIR>          ..\n",
      "29-06-2024  15:51    <DIR>          .ipynb_checkpoints\n",
      "25-06-2024  16:35            25,438 ai_feature_scoring_speech_dataset.xlsx\n",
      "13-05-2024  16:22           147,804 audio_0a2fb866-25a3-42e0-b672-a02f6b8ddd1a.m4a\n",
      "29-06-2024  16:07    <DIR>          audio_files\n",
      "29-06-2024  16:11    <DIR>          audio_files_in_mp3\n",
      "29-06-2024  16:28            39,956 Generating Feature Vector for Speeches.ipynb\n",
      "28-06-2024  15:51             1,269 Preprocess Audio.ipynb\n",
      "26-06-2024  17:45             1,312 preprocessing.py\n",
      "26-06-2024  18:19            27,334 processed_audio_sample_scoring.xlsx\n",
      "               6 File(s)        243,113 bytes\n",
      "               5 Dir(s)  922,854,739,968 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d751ec09-e12f-4426-acbf-76babe275802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"processed_audio_sample_scoring.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b1973a-9761-4540-89c7-d7897d96941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Record Audio Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>audio_beb45dff-f264-43c5-b051-61dab6a3b2a1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>audio_0e7cded9-1569-4202-98f8-59f88384437b</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>audio_08bf8a53-1e31-4d82-8979-b53a14baa196</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           Record Audio Name  Content  Pronun  \\\n",
       "0           0  audio_beb45dff-f264-43c5-b051-61dab6a3b2a1       18      11   \n",
       "1           1  audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc       70      53   \n",
       "2           2  audio_0e7cded9-1569-4202-98f8-59f88384437b       54      40   \n",
       "3           3  audio_08bf8a53-1e31-4d82-8979-b53a14baa196       28      14   \n",
       "4           4  audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d       16      11   \n",
       "\n",
       "   Fluency  feature_vector  \n",
       "0       25             NaN  \n",
       "1       64             NaN  \n",
       "2       51             NaN  \n",
       "3       36             NaN  \n",
       "4       25             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c864445f-1866-40cd-bd45-6bf67fd548d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTransformer's FeatureExtractor will normalize the inputs and put \\nthem in a format the model expects, as well as generate the other inputs that \\nthe model requires\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transformer's FeatureExtractor will normalize the inputs and put \n",
    "them in a format the model expects, as well as generate the other inputs that \n",
    "the model requires\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38df0eeb-dc50-4aef-9e99-377d69a24f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoFeatureExtractor\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4dd822-ab4d-40ba-898e-240f28001b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"processor_class\": \"Wav2Vec2Processor\",\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950d84fe-e16d-4977-aadf-bb0a99a3b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de97d6a-3892-4ff3-a7a8-eac2be7d4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x['array'] for x in examples['audio']]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate = feature_extractor.sampling_rate,\n",
    "        max_length = int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf35593b-7c2e-4652-ac7e-98a068cacf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac11f7b-57af-4ba3-9a89-319ad2ebec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a413a30-5534-4333-a565-6fe3ac5f5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 6220-5780\n",
      "\n",
      " Directory of D:\\Freelancing\\AI Feature Scoring\\training data\n",
      "\n",
      "29-06-2024  16:25    <DIR>          .\n",
      "29-06-2024  16:25    <DIR>          ..\n",
      "29-06-2024  15:51    <DIR>          .ipynb_checkpoints\n",
      "25-06-2024  16:35            25,438 ai_feature_scoring_speech_dataset.xlsx\n",
      "13-05-2024  16:22           147,804 audio_0a2fb866-25a3-42e0-b672-a02f6b8ddd1a.m4a\n",
      "29-06-2024  16:07    <DIR>          audio_files\n",
      "29-06-2024  16:11    <DIR>          audio_files_in_mp3\n",
      "29-06-2024  16:25            39,076 Generating Feature Vector for Speeches.ipynb\n",
      "28-06-2024  15:51             1,269 Preprocess Audio.ipynb\n",
      "26-06-2024  17:45             1,312 preprocessing.py\n",
      "26-06-2024  18:19            27,334 processed_audio_sample_scoring.xlsx\n",
      "               6 File(s)        242,233 bytes\n",
      "               5 Dir(s)  922,854,780,928 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cedf9ff-e4e7-4d4d-a772-c2c855ac682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(\"audio_files//audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84588dc5-7401-4415-af47-0574eb01100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_1744\\957617493.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  input_audio, sample_rate = librosa.load(path,  sr=16000)\n",
      "C:\\Users\\maste\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "path = \"audio_files//audio_fc49c5b8-0d30-4f5a-9cae-4ed06e68149d.m4a\"\n",
    "input_audio, sample_rate = librosa.load(path,  sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed0bd23-2979-48a3-bf5b-5d3f39d99da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f99ba45182044b3b9a00fdb653d2d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maste\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-large-xlsr-53. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b9123888a4be895635f3810b9c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f84e9992b274168a8ae525145f24868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'extract_features'])\n",
      "torch.Size([1, 252, 1024])\n",
      "torch.Size([1, 252, 512])\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "i= feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "# with torch.no_grad():\n",
    "#   o= model(i.input_values)\n",
    "# print(o.keys())\n",
    "# print(o.last_hidden_state.shape)\n",
    "# print(o.extract_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb39b4f-620e-49ec-a94c-45852e38420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6918,  0.3132, -1.4722,  ..., -0.4782, -1.0847,  1.3629],\n",
       "         [ 0.6918,  0.3132, -1.4722,  ..., -0.4782, -1.0847,  1.3629],\n",
       "         [ 0.0926, -0.5830, -1.5916,  ..., -0.1743, -0.6749,  0.7679],\n",
       "         ...,\n",
       "         [ 0.5284, -0.9827,  1.2669,  ...,  0.9075, -1.1282, -0.3290],\n",
       "         [ 0.7884, -1.0612,  1.3367,  ..., -0.1114, -1.2140, -0.3555],\n",
       "         [-0.2587, -1.0298,  1.5370,  ...,  0.0839, -1.2938, -0.8687]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b19e9e-5f2d-409c-bfee-73a4ac462ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.feature_extraction_utils.BatchFeature"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d96361-8fbb-49b6-b8f0-da107bae4bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[0.0003, 0.0003, 0.0003,  ..., 0.2625, 0.2615, 0.0003]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aee50d3e-455c-4a2f-91ed-8016ed93d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "def get_feature_vector(path):\n",
    "    print(f\"Loading audio from path: {path}\")\n",
    "    \n",
    "    input_audio, sample_rate = librosa.load(path, sr=16000)\n",
    "    print(\"Audio loaded successfully.\")\n",
    "    print(f\"Sample rate: {sample_rate}\")\n",
    "    print(f\"Input audio shape: {input_audio.shape}\")\n",
    "    \n",
    "    print(\"Extracting features from the audio.\")\n",
    "    features = feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "    print(\"Features extracted successfully.\")\n",
    "    print(f\"Feature shape: {features.input_values.shape}\")\n",
    "    \n",
    "    print(\"Passing features through the model.\")\n",
    "    with torch.no_grad():\n",
    "        output = model(features.input_values)\n",
    "    \n",
    "    print(\"Model inference completed.\")\n",
    "    print(f\"Output keys: {output.keys()}\")\n",
    "    print(f\"Last hidden state shape: {output.last_hidden_state.shape}\")\n",
    "    print(f\"Extracted features shape: {output.extract_features.shape}\")\n",
    "\n",
    "    print(\"************\" * 50)\n",
    "    print(\"************\" * 50)\n",
    "    print(\"************\" * 50)\n",
    "\n",
    "    return output.extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36ee8bf1-d7ef-4e31-bca1-569bc1d5c7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Record Audio Name', 'Content', 'Pronun', 'Fluency',\n",
       "       'feature_vector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06663377-d462-47e2-9503-c5997803f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_files\\audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\n",
      "Loading audio from path: audio_files\\audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\n",
      "Audio loaded successfully.\n",
      "Sample rate: 16000\n",
      "Input audio shape: (115543,)\n",
      "Extracting features from the audio.\n",
      "Features extracted successfully.\n",
      "Feature shape: torch.Size([1, 115543])\n",
      "Passing features through the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_1744\\3100802130.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  input_audio, sample_rate = librosa.load(path, sr=16000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inference completed.\n",
      "Output keys: odict_keys(['last_hidden_state', 'extract_features'])\n",
      "Last hidden state shape: torch.Size([1, 360, 1024])\n",
      "Extracted features shape: torch.Size([1, 360, 512])\n",
      "************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(audio_mp4a)):\n\u001b[0;32m     10\u001b[0m     feature_vector \u001b[38;5;241m=\u001b[39m get_feature_vector(audio_mp4a)\n\u001b[1;32m---> 11\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(audio_mp3)):\n\u001b[0;32m     14\u001b[0m     feature_vector \u001b[38;5;241m=\u001b[39m get_feature_vector(audio_mp3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    audio_mp4a = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".m4a\"\n",
    "    audio_mp3 = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".mp3\"\n",
    "    audio_wav = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".wav\"\n",
    "\n",
    "    print(audio_mp4a)\n",
    "    if(os.path.isfile(audio_mp4a)):\n",
    "        feature_vector = get_feature_vector(audio_mp4a)\n",
    "        df.at[index, \"feature_vector\"] = feature_vector\n",
    "\n",
    "    elif(os.path.isfile(audio_mp3)):\n",
    "        feature_vector = get_feature_vector(audio_mp3)\n",
    "        df.at[index, \"feature_vector\"] = feature_vector\n",
    "\n",
    "    elif(os.path.isfile(audio_wav)):\n",
    "        feature_vector = get_feature_vector(audio_wav)\n",
    "        df.at[index, \"feature_vector\"] = feature_vector\n",
    "    else:\n",
    "        print(\"bruh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afff8d-332f-4da4-a92d-bae5a77d5c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
