{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40c1d7d3-a444-48e2-a1c6-5a0ea32c031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45fd46ac-6d2f-4d27-9080-3ef33f965824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"cache_df.xlsx\")\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dddd8a16-438b-4f84-a8ab-d5ce1ecb4751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Record Audio Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>audio_beb45dff-f264-43c5-b051-61dab6a3b2a1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor([[[ 0.6925,  0.2254, -1.4681,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>tensor([[[ 0.6803,  0.1176, -1.7359,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>audio_0e7cded9-1569-4202-98f8-59f88384437b</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>tensor([[[ 0.6912,  0.2864, -1.4658,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>audio_08bf8a53-1e31-4d82-8979-b53a14baa196</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>tensor([[[ 0.7109,  0.2551, -1.6066,  ..., -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor([[[ 0.6914,  0.3067, -1.4695,  ..., -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                           Record Audio Name  \\\n",
       "0             0           0  audio_beb45dff-f264-43c5-b051-61dab6a3b2a1   \n",
       "1             1           1  audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc   \n",
       "2             2           2  audio_0e7cded9-1569-4202-98f8-59f88384437b   \n",
       "3             3           3  audio_08bf8a53-1e31-4d82-8979-b53a14baa196   \n",
       "4             4           4  audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d   \n",
       "\n",
       "   Content  Pronun  Fluency                                     feature_vector  \n",
       "0       18      11       25  tensor([[[ 0.6925,  0.2254, -1.4681,  ..., -0....  \n",
       "1       70      53       64  tensor([[[ 0.6803,  0.1176, -1.7359,  ..., -0....  \n",
       "2       54      40       51  tensor([[[ 0.6912,  0.2864, -1.4658,  ..., -0....  \n",
       "3       28      14       36  tensor([[[ 0.7109,  0.2551, -1.6066,  ..., -0....  \n",
       "4       16      11       25  tensor([[[ 0.6914,  0.3067, -1.4695,  ..., -0....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe35b8eb-2014-449b-8b64-4618b2bddcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "856313f8-a756-4598-a5fd-d0f63ded4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"feature_vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0b21db5-ccf3-497a-afc0-442a2c16a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tensor([[[ 0.6925,  0.2254, -1.4681,  ..., -0....\n",
       "1    tensor([[[ 0.6803,  0.1176, -1.7359,  ..., -0....\n",
       "2    tensor([[[ 0.6912,  0.2864, -1.4658,  ..., -0....\n",
       "3    tensor([[[ 0.7109,  0.2551, -1.6066,  ..., -0....\n",
       "4    tensor([[[ 0.6914,  0.3067, -1.4695,  ..., -0....\n",
       "5    tensor([[[ 0.6912,  0.2946, -1.4668,  ..., -0....\n",
       "6    tensor([[[ 0.6917,  0.3119, -1.4716,  ..., -0....\n",
       "7    tensor([[[ 0.6913,  0.3034, -1.4686,  ..., -0....\n",
       "8    tensor([[[ 0.6921,  0.2419, -1.4662,  ..., -0....\n",
       "9    tensor([[[ 0.6915,  0.3076, -1.4698,  ..., -0....\n",
       "Name: feature_vector, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f3e3f68-67dc-4a7b-a455-559c2a80b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for row in x:\n",
    "    print(type(row))\n",
    "\n",
    "# WOAH, GOTTA FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd105e54-b2ef-48a7-89b3-aa3430e3f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.apply(lambda w: torch.tensor(w, dtype=torch.float32) if isinstance(w, list) or isinstance(w, torch.Tensor) else w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67e829df-3a5e-4509-83ca-98752b3ce9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for row in x:\n",
    "    print(type(row))\n",
    "\n",
    "# WOAH, GOTTA FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aab7f45-0862-4d07-a795-9f52feede839",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c54912a-6b06-44b6-b7ad-d89ab4085aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_tensors \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(row, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Verify each element is a tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_tensors):\n",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_tensors \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(row, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Verify each element is a tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_tensors):\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "x_tensors = [torch.tensor(row, dtype=torch.float32) for row in x]\n",
    "\n",
    "# Verify each element is a tensor\n",
    "for i, tensor in enumerate(y_tensors):\n",
    "    print(f\"Row {i}: {tensor}, Type: {type(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec053496-60c1-4037-ae31-241300f2419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6840a9b-9197-4ffa-a322-aef65e92c268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c891582a-85ee-40e8-a333-0b4660f99ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Content\" , \"Pronun\" , \"Fluency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "338ceb65-beb2-4cf7-bd07-3d69a0379180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Content  Pronun  Fluency\n",
       "0       18      11       25\n",
       "1       70      53       64\n",
       "2       54      40       51\n",
       "3       28      14       36\n",
       "4       16      11       25\n",
       "5       48      37       34\n",
       "6       52      35       53\n",
       "7       78      62       74\n",
       "8       90      73       81\n",
       "9       90      77       74"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3520d92a-cdd5-4484-938d-86b58a592d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f87edd70-1d19-4a5b-8df4-cf58dacd2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 11, 25],\n",
       "       [70, 53, 64],\n",
       "       [54, 40, 51],\n",
       "       [28, 14, 36],\n",
       "       [16, 11, 25],\n",
       "       [48, 37, 34],\n",
       "       [52, 35, 53],\n",
       "       [78, 62, 74],\n",
       "       [90, 73, 81],\n",
       "       [90, 77, 74]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c93344c2-ccab-4085-8149-e4d35e986236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: tensor([18., 11., 25.]), Type: <class 'torch.Tensor'>\n",
      "Row 1: tensor([70., 53., 64.]), Type: <class 'torch.Tensor'>\n",
      "Row 2: tensor([54., 40., 51.]), Type: <class 'torch.Tensor'>\n",
      "Row 3: tensor([28., 14., 36.]), Type: <class 'torch.Tensor'>\n",
      "Row 4: tensor([16., 11., 25.]), Type: <class 'torch.Tensor'>\n",
      "Row 5: tensor([48., 37., 34.]), Type: <class 'torch.Tensor'>\n",
      "Row 6: tensor([52., 35., 53.]), Type: <class 'torch.Tensor'>\n",
      "Row 7: tensor([78., 62., 74.]), Type: <class 'torch.Tensor'>\n",
      "Row 8: tensor([90., 73., 81.]), Type: <class 'torch.Tensor'>\n",
      "Row 9: tensor([90., 77., 74.]), Type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y_tensors = [torch.tensor(row, dtype=torch.float32) for row in y_np]\n",
    "\n",
    "# Verify each element is a tensor\n",
    "for i, tensor in enumerate(y_tensors):\n",
    "    print(f\"Row {i}: {tensor}, Type: {type(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86f9c9dc-3ae2-4b3c-94da-1a5ef8fc9f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([18., 11., 25.]),\n",
       " tensor([70., 53., 64.]),\n",
       " tensor([54., 40., 51.]),\n",
       " tensor([28., 14., 36.]),\n",
       " tensor([16., 11., 25.]),\n",
       " tensor([48., 37., 34.]),\n",
       " tensor([52., 35., 53.]),\n",
       " tensor([78., 62., 74.]),\n",
       " tensor([90., 73., 81.]),\n",
       " tensor([90., 77., 74.])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ae6240-2fa0-4ba5-8ef1-eca2fcbef2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26b4851c-5def-4224-8fcc-d3c46e1833bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tensor([[[ 0.6925,  0.2254, -1.4681,  ..., -0....\n",
      "1    tensor([[[ 0.6803,  0.1176, -1.7359,  ..., -0....\n",
      "2    tensor([[[ 0.6912,  0.2864, -1.4658,  ..., -0....\n",
      "3    tensor([[[ 0.7109,  0.2551, -1.6066,  ..., -0....\n",
      "4    tensor([[[ 0.6914,  0.3067, -1.4695,  ..., -0....\n",
      "5    tensor([[[ 0.6912,  0.2946, -1.4668,  ..., -0....\n",
      "6    tensor([[[ 0.6917,  0.3119, -1.4716,  ..., -0....\n",
      "7    tensor([[[ 0.6913,  0.3034, -1.4686,  ..., -0....\n",
      "8    tensor([[[ 0.6921,  0.2419, -1.4662,  ..., -0....\n",
      "9    tensor([[[ 0.6915,  0.3076, -1.4698,  ..., -0....\n",
      "Name: feature_vector, dtype: object\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a85f2f2-f524-4b6e-b3ec-b96f740949f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([18., 11., 25.]), tensor([70., 53., 64.]), tensor([54., 40., 51.]), tensor([28., 14., 36.]), tensor([16., 11., 25.]), tensor([48., 37., 34.]), tensor([52., 35., 53.]), tensor([78., 62., 74.]), tensor([90., 73., 81.]), tensor([90., 77., 74.])]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece765f1-dbbf-4080-9c47-cdcbba92d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "wav2vec2_model = Wav2Vec2Model.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b3360-dcf7-405a-a70d-990d95103881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): Wav2Vec2FeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "      (conv): ParametrizedConv1d(\n",
       "        1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _WeightNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (padding): Wav2Vec2SamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2475d1f0-bffa-4305-bb7f-bf3b321d1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_activation(x):\n",
    "    return 10 * tf.nn.sigmoid(x)\n",
    "    \n",
    "class Wav2Vec2ForScoring(tf.keras.Model):\n",
    "    def __init__(self , wav2vec2_model , num_classes):\n",
    "        super().__init__()\n",
    "        self.wav2vec2_model = wav2vec2_model\n",
    "        self.fc = tf.keras.layers.Dense(num_classes , activation = custom_activation)\n",
    "    \n",
    "    def call(self , inputs):\n",
    "        # pass the inputs to the bert model\n",
    "        x = self.wav2vec3_model(inputs)\n",
    "        # the model outputs: last_hidden state and pooler_output\n",
    "        # these are the logits with respect to bert\n",
    "        x = x[1]\n",
    "        # since we only wanted the pooler_output\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7468a24a-dd9f-4228-900d-1a7ce90dca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_model = Wav2Vec2ForScoring(wav2vec2_model , num_classes = 3)\n",
    "\n",
    "scoring_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8e894b-574a-400e-a435-c8c2973515ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Wav2Vec2ForScoring name=wav2_vec2_for_scoring_1, built=False>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73de65c2-99f9-4b10-97af-c726c694a089",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m scoring_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     (x , y),\n\u001b[0;32m      3\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n"
     ]
    }
   ],
   "source": [
    "history = scoring_model.fit(\n",
    "    (x , y),\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7443c-a35e-48eb-9964-9c4d7653b851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
