{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2fe6be-f642-4af9-826c-5bfdd2b635e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\maste\\anaconda3\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maste\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\maste\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\maste\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\maste\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\maste\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maste\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47698f5a-5b3d-45e5-ab57-44b261ae9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/wav2vec2-conformer-rel-pos-large\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad1a5b8-547b-4287-a296-9ff1bfb59e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 6220-5780\n",
      "\n",
      " Directory of D:\\Freelancing\\AI Feature Scoring\\training data\n",
      "\n",
      "30-06-2024  10:14    <DIR>          .\n",
      "30-06-2024  10:14    <DIR>          ..\n",
      "30-06-2024  10:10    <DIR>          .ipynb_checkpoints\n",
      "25-06-2024  16:35            25,438 ai_feature_scoring_speech_dataset.xlsx\n",
      "13-05-2024  16:22           147,804 audio_0a2fb866-25a3-42e0-b672-a02f6b8ddd1a.m4a\n",
      "29-06-2024  17:48    <DIR>          audio_files\n",
      "29-06-2024  16:11    <DIR>          audio_files_in_mp3\n",
      "30-06-2024  10:14         1,366,623 Generating Feature Vector for Speeches.ipynb\n",
      "28-06-2024  15:51             1,269 Preprocess Audio.ipynb\n",
      "26-06-2024  17:45             1,312 preprocessing.py\n",
      "26-06-2024  18:19            27,334 processed_audio_sample_scoring.xlsx\n",
      "30-06-2024  10:12               617 Untitled.ipynb\n",
      "               7 File(s)      1,570,397 bytes\n",
      "               5 Dir(s)  923,343,032,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d751ec09-e12f-4426-acbf-76babe275802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"processed_audio_sample_scoring.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4b1973a-9761-4540-89c7-d7897d96941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Record Audio Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>feature_vector</th>\n",
       "      <th>primary key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>audio_beb45dff-f264-43c5-b051-61dab6a3b2a1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e8164bd2-334b-4d80-a775-df8321fcccfa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234f2f41-82a2-4420-8b5e-39fd0a45e02a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>audio_0e7cded9-1569-4202-98f8-59f88384437b</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0882b978-d9b6-488c-826d-f65edaa0c69e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>audio_08bf8a53-1e31-4d82-8979-b53a14baa196</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7f773fc0-f0d2-4327-a09c-abc9706ca3ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ed82c27b-4c29-4fa6-b008-dd7e40fe01cd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                           Record Audio Name  \\\n",
       "0             0           0  audio_beb45dff-f264-43c5-b051-61dab6a3b2a1   \n",
       "1             1           1  audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc   \n",
       "2             2           2  audio_0e7cded9-1569-4202-98f8-59f88384437b   \n",
       "3             3           3  audio_08bf8a53-1e31-4d82-8979-b53a14baa196   \n",
       "4             4           4  audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d   \n",
       "\n",
       "   Content  Pronun  Fluency  feature_vector  \\\n",
       "0       18      11       25             NaN   \n",
       "1       70      53       64             NaN   \n",
       "2       54      40       51             NaN   \n",
       "3       28      14       36             NaN   \n",
       "4       16      11       25             NaN   \n",
       "\n",
       "                            primary key  \n",
       "0  e8164bd2-334b-4d80-a775-df8321fcccfa  \n",
       "1  234f2f41-82a2-4420-8b5e-39fd0a45e02a  \n",
       "2  0882b978-d9b6-488c-826d-f65edaa0c69e  \n",
       "3  7f773fc0-f0d2-4327-a09c-abc9706ca3ea  \n",
       "4  ed82c27b-4c29-4fa6-b008-dd7e40fe01cd  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c864445f-1866-40cd-bd45-6bf67fd548d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTransformer's FeatureExtractor will normalize the inputs and put \\nthem in a format the model expects, as well as generate the other inputs that \\nthe model requires\\n\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transformer's FeatureExtractor will normalize the inputs and put \n",
    "them in a format the model expects, as well as generate the other inputs that \n",
    "the model requires\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38df0eeb-dc50-4aef-9e99-377d69a24f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoFeatureExtractor\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe4dd822-ab4d-40ba-898e-240f28001b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "950d84fe-e16d-4977-aadf-bb0a99a3b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de97d6a-3892-4ff3-a7a8-eac2be7d4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x['array'] for x in examples['audio']]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate = feature_extractor.sampling_rate,\n",
    "        max_length = int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf35593b-7c2e-4652-ac7e-98a068cacf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac11f7b-57af-4ba3-9a89-319ad2ebec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a413a30-5534-4333-a565-6fe3ac5f5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 6220-5780\n",
      "\n",
      " Directory of D:\\Freelancing\\AI Feature Scoring\\training data\n",
      "\n",
      "30-06-2024  10:18    <DIR>          .\n",
      "30-06-2024  10:18    <DIR>          ..\n",
      "30-06-2024  10:10    <DIR>          .ipynb_checkpoints\n",
      "25-06-2024  16:35            25,438 ai_feature_scoring_speech_dataset.xlsx\n",
      "13-05-2024  16:22           147,804 audio_0a2fb866-25a3-42e0-b672-a02f6b8ddd1a.m4a\n",
      "29-06-2024  17:48    <DIR>          audio_files\n",
      "29-06-2024  16:11    <DIR>          audio_files_in_mp3\n",
      "30-06-2024  10:16            28,835 Generating Feature Vector for Speeches.ipynb\n",
      "28-06-2024  15:51             1,269 Preprocess Audio.ipynb\n",
      "26-06-2024  17:45             1,312 preprocessing.py\n",
      "26-06-2024  18:19            27,334 processed_audio_sample_scoring.xlsx\n",
      "30-06-2024  10:18             6,307 Untitled.ipynb\n",
      "               7 File(s)        238,299 bytes\n",
      "               5 Dir(s)  923,344,359,424 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cedf9ff-e4e7-4d4d-a772-c2c855ac682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isfile(\"audio_files//audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "385eb9d0-b552-4b83-92a5-54ff4cb0bde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(7)\n",
    "# Default: pad with zeros\n",
    "librosa.util.fix_length(y, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ddce1-e829-4cbc-aecb-f25b4f861afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84588dc5-7401-4415-af47-0574eb01100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370944,)\n",
      "[-3.0695446e-12  4.0927262e-12 -6.7075234e-12 ... -8.9232650e-05\n",
      " -7.0825663e-05 -8.1021644e-05]\n",
      "(90000,)\n",
      "[-3.0695446e-12  4.0927262e-12 -6.7075234e-12 ...  5.6623062e-04\n",
      " -1.6612799e-03 -9.4101555e-04]\n"
     ]
    }
   ],
   "source": [
    "path = \"audio_files//3d72dc66-cf86-463c-8d1c-62015abd2ada.mp3\"\n",
    "input_audio, sample_rate = librosa.load(path,  sr=16000)\n",
    "print(input_audio.shape)\n",
    "print(input_audio)\n",
    "input_audio = librosa.util.fix_length(input_audio, size = 90000)\n",
    "print(input_audio.shape)\n",
    "print(input_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0009bf05-9bef-4e2e-a7eb-04c083375581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0695446e-12,  4.0927262e-12, -6.7075234e-12, ...,\n",
       "        5.6623062e-04, -1.6612799e-03, -9.4101555e-04], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c90678-4274-4417-af08-d829f4492a1d",
   "metadata": {},
   "source": [
    "### STANDARDIZING DIGITAL AUDIO LENGTH TO BE ROUGHLY 40 SECONDS I.E (620000 , ) witih respect to librosa frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed0bd23-2979-48a3-bf5b-5d3f39d99da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'extract_features'])\n",
      "torch.Size([1, 281, 1024])\n",
      "torch.Size([1, 281, 512])\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "i= feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "with torch.no_grad():\n",
    "    o= model(i.input_values)\n",
    "    print(o.keys())\n",
    "    print(o.last_hidden_state.shape)\n",
    "    print(o.extract_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eb39b4f-620e-49ec-a94c-45852e38420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6894,  0.3180, -1.4760,  ..., -0.4803, -1.0797,  1.3792],\n",
       "         [ 0.8018, -0.1305, -1.8103,  ..., -0.3512, -1.0239,  2.1004],\n",
       "         [ 0.0443, -1.1676, -0.5069,  ...,  0.2634, -0.7515,  1.9273],\n",
       "         ...,\n",
       "         [ 1.0093, -0.9408, -0.9136,  ..., -0.2134, -0.5997, -0.4580],\n",
       "         [ 0.5116, -0.9225, -0.5452,  ...,  0.2268, -0.8276,  0.0999],\n",
       "         [ 0.0520, -1.0261, -0.2943,  ...,  0.3316, -0.2119,  0.7896]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b19e9e-5f2d-409c-bfee-73a4ac462ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.feature_extraction_utils.BatchFeature"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d96361-8fbb-49b6-b8f0-da107bae4bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[ 0.0004,  0.0004,  0.0004,  ...,  0.0065, -0.0178, -0.0099]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edba51f-f5f4-4b14-b9fe-88ecd7ac4c7f",
   "metadata": {},
   "source": [
    "### Loading the MongoDB Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "10e6b065-a815-4ba2-9f56-3fdf248375da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "Collections in Speech_Feature_Vectors database:\n",
      "['main_collection']\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection URI\n",
    "uri = \"mongodb+srv://bartwalkartikey1:strongandcapable@cluster0.nhigta4.mongodb.net/?appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Access your specific database\n",
    "mongo_db = client.Speech_Feature_Vectors\n",
    "\n",
    "# Print collection names to verify\n",
    "print(\"Collections in Speech_Feature_Vectors database:\")\n",
    "print(mongo_db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b29d96c5-175a-4d6e-b0ec-7b6015fbb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMongoDB Database Schema\\n\\n1) primary_key: \\n2) audio_file_name:\\n3) feature_vector_ascii:\\n4) question:\\n5) content:\\n6) pronunciation:\\n7) fluency:\\n'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MongoDB Database Schema\n",
    "\n",
    "1) primary_key: \n",
    "2) audio_file_name:\n",
    "3) feature_vector_ascii:\n",
    "4) question:\n",
    "5) content:\n",
    "6) pronunciation:\n",
    "7) fluency:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aee50d3e-455c-4a2f-91ed-8016ed93d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "def get_feature_vector(path):\n",
    "    print(f\"Loading audio from path: {path}\")\n",
    "    \n",
    "    input_audio, sample_rate = librosa.load(path, sr=16000)\n",
    "    print(\"Audio loaded successfully.\")\n",
    "    print(f\"Sample rate: {sample_rate}\")\n",
    "    print(f\"Input audio shape: {input_audio.shape}\")\n",
    "\n",
    "    # Adding padding to make sure the audio perfectly fits the 40 seconds frame\n",
    "    desired_length = 620000  # Adjust this according to your requirement\n",
    "    print(f\"Padding audio to achieve desired length: {desired_length}\")\n",
    "    input_audio = librosa.util.fix_length(input_audio, size=desired_length)\n",
    "    print(f\"Padded audio shape: {input_audio.shape}\")\n",
    "\n",
    "    print(\"Extracting features from the audio.\")\n",
    "    features = feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "    print(\"Features extracted successfully.\")\n",
    "    print(f\"Feature shape: {features.input_values.shape}\")\n",
    "    \n",
    "    print(\"Passing features through the model.\")\n",
    "    with torch.no_grad():\n",
    "        output = model(features.input_values)\n",
    "    \n",
    "    print(\"Model inference completed.\")\n",
    "    print(f\"Output keys: {output.keys()}\")\n",
    "    print(f\"Last hidden state shape: {output.last_hidden_state.shape}\")\n",
    "    print(f\"Extracted features shape: {output.extract_features.shape}\")\n",
    "\n",
    "    print(\"************\" * 50)\n",
    "    print(\"************\" * 50)\n",
    "    print(\"************\" * 50)\n",
    "    feature_vector_numpy = output.extract_features.numpy()\n",
    "\n",
    "\n",
    "    # ENCODE THE FEATURE VECTOR IN STRING/BYTES REPRESENTATION DUE TO THE LIMITATIONS OF PANDAS \n",
    "    string_repr = base64.binascii.b2a_base64(feature_vector_numpy).decode(\"ascii\")\n",
    "\n",
    "    print(\"Encoded this into a string format so that our pandas dataframe can save it\")\n",
    "    \n",
    "    return string_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36ee8bf1-d7ef-4e31-bca1-569bc1d5c7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Record Audio Name', 'Content', 'Pronun', 'Fluency',\n",
       "       'feature_vector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1fd1b547-769d-4e6b-a629-9f05769a831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0 , \"feature_vector\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "926d945c-89c7-4ad5-984a-9b1a7fdfd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06663377-d462-47e2-9503-c5997803f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current index:  0\n",
      "audio_files\\audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\n",
      "Loading audio from path: audio_files\\audio_beb45dff-f264-43c5-b051-61dab6a3b2a1.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_4676\\3186860062.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  input_audio, sample_rate = librosa.load(path, sr=16000)\n",
      "C:\\Users\\maste\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded successfully.\n",
      "Sample rate: 16000\n",
      "Input audio shape: (115543,)\n",
      "Padding audio to achieve desired length: 620000\n",
      "Padded audio shape: (620000,)\n",
      "Extracting features from the audio.\n",
      "Features extracted successfully.\n",
      "Feature shape: torch.Size([1, 620000])\n",
      "Passing features through the model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(\"current index: \" , index)\n",
    "    audio_mp4a = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".m4a\"\n",
    "    audio_mp3 = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".mp3\"\n",
    "    audio_wav = \"audio_files\\\\\" + row[\"Record Audio Name\"] + \".wav\"\n",
    "    if(index == 10):\n",
    "        break;\n",
    "    \n",
    "    print(audio_mp4a)\n",
    "    if(os.path.isfile(audio_mp4a)):\n",
    "        feature_vector_ascii = get_feature_vector(audio_mp4a)\n",
    "        primary_key = row[\"primary key\"]\n",
    "        content = row[\"Content\"]\n",
    "        question = \"null\"\n",
    "        pronunciation = row[\"pronun\"]\n",
    "        fluency = row[\"Fluency\"]\n",
    "        audio_file_name = row[\"Record Audio Name\"]\n",
    "        \n",
    "        mongo_db.main_collection.insert({\n",
    "            \"primary_key\": primary_key,\n",
    "            \"audio_file_name\": audio_file_name,\n",
    "            \"question\": question,\n",
    "            \"feature_vector_ascii\": feature_vector_ascii,\n",
    "            \"content\" : content,\n",
    "            \"pronunciation\" : pronunciation,\n",
    "            \"fluency\" : fluency\n",
    "        })\n",
    "    \n",
    "\n",
    "    elif(os.path.isfile(audio_mp3)):\n",
    "        feature_vector_ascii = get_feature_vector(audio_mp4a)\n",
    "        primary_key = row[\"primary key\"]\n",
    "        content = row[\"Content\"]\n",
    "        question = \"null\"\n",
    "        pronunciation = row[\"pronun\"]\n",
    "        fluency = row[\"Fluency\"]\n",
    "        audio_file_name = row[\"Record Audio Name\"]\n",
    "        \n",
    "        mongo_db.main_collection.insert({\n",
    "            \"primary_key\": primary_key,\n",
    "            \"audio_file_name\": audio_file_name,\n",
    "            \"question\": question,\n",
    "            \"feature_vector_ascii\": feature_vector_ascii,\n",
    "            \"content\" : content,\n",
    "            \"pronunciation\" : pronunciation,\n",
    "            \"fluency\" : fluency\n",
    "        })\n",
    "\n",
    "    \n",
    "    elif(os.path.isfile(audio_wav)):\n",
    "        feature_vector_ascii = get_feature_vector(audio_mp4a)\n",
    "        primary_key = row[\"primary key\"]\n",
    "        content = row[\"Content\"]\n",
    "        question = \"null\"\n",
    "        pronunciation = row[\"pronun\"]\n",
    "        fluency = row[\"Fluency\"]\n",
    "        audio_file_name = row[\"Record Audio Name\"]\n",
    "        \n",
    "        mongo_db.main_collection.insert({\n",
    "            \"primary_key\": primary_key,\n",
    "            \"audio_file_name\": audio_file_name,\n",
    "            \"question\": question,\n",
    "            \"feature_vector_ascii\": feature_vector_ascii,\n",
    "            \"content\" : content,\n",
    "            \"pronunciation\" : pronunciation,\n",
    "            \"fluency\" : fluency\n",
    "        })\n",
    "   \n",
    "    else:\n",
    "        print(\"bruh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36afff8d-332f-4da4-a92d-bae5a77d5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1937, 512)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34f37f89-8ea6-496f-b8a0-1eccca37b0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.69147277,  0.30756503, -1.4698067 , ..., -0.47657296,\n",
       "         -1.0872273 ,  1.3522896 ],\n",
       "        [ 0.6913694 ,  0.31077218, -1.4723892 , ..., -0.47656566,\n",
       "         -1.0858618 ,  1.3551285 ],\n",
       "        [-0.3305185 ,  0.14563823,  0.16405821, ..., -0.28315535,\n",
       "         -1.1845428 ,  0.2766222 ],\n",
       "        ...,\n",
       "        [ 0.69147277,  0.30756503, -1.4698067 , ..., -0.47657296,\n",
       "         -1.0872273 ,  1.3522896 ],\n",
       "        [ 0.69147277,  0.30756503, -1.4698067 , ..., -0.47657296,\n",
       "         -1.0872273 ,  1.3522896 ],\n",
       "        [ 0.69147277,  0.30756503, -1.4698067 , ..., -0.47657296,\n",
       "         -1.0872273 ,  1.3522896 ]]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e7d00216-4b29-4400-9ec3-b9429f18f3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5289305"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5f16e104-6531-4d7f-a067-e33fab330d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "string_repr = base64.binascii.b2a_base64(feature_vector).decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "102e9a88-ffdb-4f97-9cef-adc556d5e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.frombuffer(base64.binascii.a2b_base64(string_repr.encode(\"ascii\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "976474d0-b855-417c-bd3e-780b822e7579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495872,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19c7a24b-d8bd-4aa0-b101-ef1bc92deb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "random_array = np.random.randn(32,32)\n",
    "string_repr = base64.binascii.b2a_base64(random_array).decode(\"ascii\")\n",
    "array = np.frombuffer(base64.binascii.a2b_base64(string_repr.encode(\"ascii\"))) \n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "394b2671-68d7-4650-93be-85c446bad0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "72e16a5e-4b47-4eaa-be1d-a835a2b9c4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.23542334,  0.42521483, -1.81058111, ..., -0.84198511,\n",
       "        -0.58417977, -0.08156493],\n",
       "       [ 0.51322353,  0.48519351,  0.40519151, ...,  0.34791843,\n",
       "        -0.55194965, -0.79670938],\n",
       "       [ 0.57667845, -0.61750494,  1.38764963, ..., -0.62667268,\n",
       "        -0.5592191 , -0.76837245],\n",
       "       ...,\n",
       "       [ 0.38065372,  1.96137609, -1.7645145 , ...,  1.22487971,\n",
       "         1.52380943, -1.17364911],\n",
       "       [ 1.20651442, -0.35671541,  0.65394851, ..., -0.08418966,\n",
       "        -0.94843558, -0.9041878 ],\n",
       "       [ 0.53957967,  1.45826843, -0.87558543, ...,  0.77859823,\n",
       "        -0.42627661, -0.46979751]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0bcc7-129d-4b9d-b9b8-c8bbb2201317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61bb47-5f6e-4475-b6eb-4cfac0c63f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc239e1-63ec-4514-894f-d4cc825a04f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "325b2cad-f226-4098-9146-034773dadbeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming feature_vector is your PyTorch tensor\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m feature_vector_numpy \u001b[38;5;241m=\u001b[39m feature_vector\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_vector_numpy)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(feature_vector_numpy))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming feature_vector is your PyTorch tensor\n",
    "feature_vector_numpy = feature_vector.numpy()\n",
    "\n",
    "print(feature_vector_numpy)\n",
    "print(type(feature_vector_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b09b0-ec00-4084-8df2-98dade361b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9703780-8a7f-4024-a0c4-08f6e8fb58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature_vector'] = df['feature_vector'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "063ab2ba-dbe2-4790-bc13-60dee8fd1939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_4676\\2852518776.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"feature_vector\"][0] = feature_vector\n"
     ]
    }
   ],
   "source": [
    "df[\"feature_vector\"][0] = feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "303bbc81-0be3-47ef-b0f2-e1c7940d7b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 410 entries, 0 to 409\n",
      "Series name: feature_vector\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "10 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df[\"feature_vector\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "735f8083-9068-4d64-b5b5-b531b3d1dc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 6)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fc3fa86-09ac-48a6-8389-81dd1612fe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Record Audio Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>audio_beb45dff-f264-43c5-b051-61dab6a3b2a1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>[[[0.69147277, 0.30756503, -1.4698067, 0.18352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>[[[0.680308, 0.11757538, -1.7359407, 0.7835479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>audio_0e7cded9-1569-4202-98f8-59f88384437b</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>[[[0.691213, 0.28636953, -1.4657668, 0.1466033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>audio_08bf8a53-1e31-4d82-8979-b53a14baa196</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>[[[0.7108567, 0.25508475, -1.6066024, 0.574884...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>[[[0.6914394, 0.30674523, -1.4695339, 0.181607...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           Record Audio Name  Content  Pronun  \\\n",
       "0           0  audio_beb45dff-f264-43c5-b051-61dab6a3b2a1       18      11   \n",
       "1           1  audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc       70      53   \n",
       "2           2  audio_0e7cded9-1569-4202-98f8-59f88384437b       54      40   \n",
       "3           3  audio_08bf8a53-1e31-4d82-8979-b53a14baa196       28      14   \n",
       "4           4  audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d       16      11   \n",
       "\n",
       "   Fluency                                     feature_vector  \n",
       "0       25  [[[0.69147277, 0.30756503, -1.4698067, 0.18352...  \n",
       "1       64  [[[0.680308, 0.11757538, -1.7359407, 0.7835479...  \n",
       "2       51  [[[0.691213, 0.28636953, -1.4657668, 0.1466033...  \n",
       "3       36  [[[0.7108567, 0.25508475, -1.6066024, 0.574884...  \n",
       "4       25  [[[0.6914394, 0.30674523, -1.4695339, 0.181607...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f9f614f1-283d-433b-91e9-67ab60945225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"feature_engineered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4f401-54b9-43d2-844b-ee7f72af7d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9f1e4-6c03-4acc-ad6f-8009853287ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d06c8-4990-4c84-aced-f4c7a20d21f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
