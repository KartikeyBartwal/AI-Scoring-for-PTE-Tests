{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "40c1d7d3-a444-48e2-a1c6-5a0ea32c031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45fd46ac-6d2f-4d27-9080-3ef33f965824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"cache_df.xlsx\")\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "593f4729-bc5f-4b64-bf76-bdf137a3ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['feature_vector'] = df['feature_vector'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dddd8a16-438b-4f84-a8ab-d5ce1ecb4751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Record Audio Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>audio_beb45dff-f264-43c5-b051-61dab6a3b2a1</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>9kUxP7DPZj4K67u/1Fm3PaSv8z5Rrrm+X4OWPsT3Ub+4qp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>qiguP1zL8D1OM96/mJZIPyrYfz8ko1e+ZSDEPkZgUr+AKC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>audio_0e7cded9-1569-4202-98f8-59f88384437b</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>VvMwPwefkj4/nru/Mh8WPiorAz/Cory+M/yUPnRlUr8Au+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>audio_08bf8a53-1e31-4d82-8979-b53a14baa196</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>tPo1P3iagj4mpc2/pSsTP5CaSD/mVIW+KkacPqL5a7+6T/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>LAIxP7YNnT6wGby/QPc5Pv2QCD8KFru+C7CTPrTKVb/YTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                           Record Audio Name  \\\n",
       "0             0           0  audio_beb45dff-f264-43c5-b051-61dab6a3b2a1   \n",
       "1             1           1  audio_f86da9b5-9ed2-4153-9508-e59448e7d8bc   \n",
       "2             2           2  audio_0e7cded9-1569-4202-98f8-59f88384437b   \n",
       "3             3           3  audio_08bf8a53-1e31-4d82-8979-b53a14baa196   \n",
       "4             4           4  audio_a3b474a9-3b8e-4533-aa95-0cda51f1395d   \n",
       "\n",
       "   Content  Pronun  Fluency                                     feature_vector  \n",
       "0       18      11       25  9kUxP7DPZj4K67u/1Fm3PaSv8z5Rrrm+X4OWPsT3Ub+4qp...  \n",
       "1       70      53       64  qiguP1zL8D1OM96/mJZIPyrYfz8ko1e+ZSDEPkZgUr+AKC...  \n",
       "2       54      40       51  VvMwPwefkj4/nru/Mh8WPiorAz/Cory+M/yUPnRlUr8Au+...  \n",
       "3       28      14       36  tPo1P3iagj4mpc2/pSsTP5CaSD/mVIW+KkacPqL5a7+6T/...  \n",
       "4       16      11       25  LAIxP7YNnT6wGby/QPc5Pv2QCD8KFru+C7CTPrTKVb/YTA...  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe35b8eb-2014-449b-8b64-4618b2bddcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5d638-9104-462f-8c6a-3871caa36202",
   "metadata": {},
   "source": [
    "### Load the feature vectors corresponding to the primary keys (feature vectors are stored in MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0372059f-f271-4191-87ff-5a3bce6cb416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo==3.11 (from pymongo[srv]==3.11)\n",
      "  Downloading pymongo-3.11.0.tar.gz (771 kB)\n",
      "     ---------------------------------------- 0.0/771.7 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/771.7 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/771.7 kB ? eta -:--:--\n",
      "      ------------------------------------ 20.5/771.7 kB 165.2 kB/s eta 0:00:05\n",
      "     - ----------------------------------- 41.0/771.7 kB 245.8 kB/s eta 0:00:03\n",
      "     ---- ------------------------------- 102.4/771.7 kB 492.8 kB/s eta 0:00:02\n",
      "     -------------------- ----------------- 409.6/771.7 kB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 771.7/771.7 kB 2.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting dnspython<2.0.0,>=1.16.0 (from pymongo[srv]==3.11)\n",
      "  Downloading dnspython-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
      "   ---------------------------------------- 0.0/188.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 188.4/188.4 kB 11.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pymongo\n",
      "  Building wheel for pymongo (setup.py): started\n",
      "  Building wheel for pymongo (setup.py): finished with status 'done'\n",
      "  Created wheel for pymongo: filename=pymongo-3.11.0-cp311-cp311-win_amd64.whl size=379704 sha256=fc4595c6f72ff419c2933bde1619e7ab66ec80b8c19ae457b2d2b50e3f257ebe\n",
      "  Stored in directory: c:\\users\\maste\\appdata\\local\\pip\\cache\\wheels\\43\\00\\27\\6d27c275881078538e7cd04e595f2f3a1f14b1ef9e32e40583\n",
      "Successfully built pymongo\n",
      "Installing collected packages: pymongo, dnspython\n",
      "Successfully installed dnspython-1.16.0 pymongo-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pymongo[srv]\"==3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5f1db18e-f951-4af9-9408-871f71817669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "Collections in Speech_Feature_Vectors database:\n",
      "['main_collection']\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection URI\n",
    "uri = \"mongodb+srv://bartwalkartikey1:strongandcapable@cluster0.nhigta4.mongodb.net/?appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Access your specific database\n",
    "mongo_db = client.Speech_Feature_Vectors\n",
    "\n",
    "# Print collection names to verify\n",
    "print(\"Collections in Speech_Feature_Vectors database:\")\n",
    "print(mongo_db.list_collection_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d9230dfa-a666-489b-9abe-75bee742bca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['ac-ogfvysq-shard-00-00.nhigta4.mongodb.net:27017', 'ac-ogfvysq-shard-00-02.nhigta4.mongodb.net:27017', 'ac-ogfvysq-shard-00-01.nhigta4.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, appname='Cluster0', authsource='admin', replicaset='atlas-4duzij-shard-0', ssl=True)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "66efb4b2-7629-4080-bdfc-9abed4cf101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_db = client.Speech_Feature_Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e8a211df-2c95-4289-a7a5-d67e35f651c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['ac-ogfvysq-shard-00-00.nhigta4.mongodb.net:27017', 'ac-ogfvysq-shard-00-02.nhigta4.mongodb.net:27017', 'ac-ogfvysq-shard-00-01.nhigta4.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, appname='Cluster0', authsource='admin', replicaset='atlas-4duzij-shard-0', ssl=True), 'Speech_Feature_Vectors')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8c2886f4-e0ef-4039-bb5c-e31ccc80107c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main_collection']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3926bdcc-4143-42dc-bb66-0acb8427f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_7672\\773180336.py:1: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  mongo_db.main_collection.insert(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('66810b0ac1c2d6f6e4de2add')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_db.main_collection.insert(\n",
    "    {\"name\" : \"kartikey\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795ceee-2297-45a5-88ae-65bde4a16900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcdf64-2ccb-42b1-ba23-c419cf38a5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "856313f8-a756-4598-a5fd-d0f63ded4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df[\"feature_vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d0b21db5-ccf3-497a-afc0-442a2c16a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9kUxP7DPZj4K67u/1Fm3PaSv8z5Rrrm+X4OWPsT3Ub+4qp...\n",
       "1    qiguP1zL8D1OM96/mJZIPyrYfz8ko1e+ZSDEPkZgUr+AKC...\n",
       "2    VvMwPwefkj4/nru/Mh8WPiorAz/Cory+M/yUPnRlUr8Au+...\n",
       "3    tPo1P3iagj4mpc2/pSsTP5CaSD/mVIW+KkacPqL5a7+6T/...\n",
       "4    LAIxP7YNnT6wGby/QPc5Pv2QCD8KFru+C7CTPrTKVb/YTA...\n",
       "5    jPIwP4zWlj4jv7u/ZHAiPt8MBT9PSry+poGUPtpdU79Ac/...\n",
       "6    /hQxP0W1nz6WXLy/AMVHPjKXCj/nG7q+kEqTPsR7V7/wEB...\n",
       "7    /PowP79cmz4k+ru/pKcyPr57Bz8sh7u+oOyTPhb4VL8UOg...\n",
       "8    aCwxP4a3dz7OrLu/2GXQPXDB9z7BO7u+noCWPoZcUb+4o6...\n",
       "9    XAQxPyp5nT6gIry/dO07PvPaCD9R9bq+maCTPq4FVr+E8w...\n",
       "Name: feature_vector, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "123bcd98-d4c9-4e6a-817a-c6b0c5942fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ascii_to_numpy(string_repr):\n",
    "#     print(type(string_repr))\n",
    "#     return np.frombuffer(base64.binascii.a2b_base64(string_repr.encode(\"ascii\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2d357dd9-1d0a-413e-bd20-cd2dc8f8bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.empty((0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "41a07b17-2786-4214-b18b-882a1020a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Incorrect padding",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(row))\n\u001b[1;32m----> 4\u001b[0m vector \u001b[38;5;241m=\u001b[39m ascii_to_numpy(row)\n",
      "Cell \u001b[1;32mIn[156], line 3\u001b[0m, in \u001b[0;36mascii_to_numpy\u001b[1;34m(string_repr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mascii_to_numpy\u001b[39m(string_repr):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(string_repr))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(base64\u001b[38;5;241m.\u001b[39mbinascii\u001b[38;5;241m.\u001b[39ma2b_base64(string_repr\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[1;31mError\u001b[0m: Incorrect padding"
     ]
    }
   ],
   "source": [
    "# for row in df[\"feature_vector\"]:\n",
    "#     print(len(row))\n",
    "#     print(type(row))\n",
    "#     vector = ascii_to_numpy(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0f46b-f8d7-4c61-bbdb-43b7715b7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a829b-d363-49c4-8ae9-4d461b955881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d6d5f8f8-6a71-4384-91d9-68bdbf632cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4ad6be8-5571-4df3-bdd4-a90a05fa5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Example DataFrame\n",
    "# data = {\n",
    "#     'feature_vector': [\n",
    "#         np.array([1, 2, 3]),\n",
    "#         np.array([4, 5, 6]),\n",
    "#         np.array([7, 8, 9])\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "78522680-b87b-4ab3-af93-8acd6d4cdcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for row in df[\"feature_vector\"]:\n",
    "    print(type(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "69f68cc4-f29c-4fe6-a68f-2c7532a49bd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '...'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(numbers)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1937\u001b[39m, \u001b[38;5;241m512\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply the function to each element in 'feature_vector'\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(parse_and_reshape)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Verify the dtype of the column\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_vector\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[137], line 5\u001b[0m, in \u001b[0;36mparse_and_reshape\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Split into individual numbers and convert to float\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m numbers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert list to numpy array and reshape\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(numbers)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1937\u001b[39m, \u001b[38;5;241m512\u001b[39m))\n",
      "Cell \u001b[1;32mIn[137], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Split into individual numbers and convert to float\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m numbers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert list to numpy array and reshape\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(numbers)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1937\u001b[39m, \u001b[38;5;241m512\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '...'"
     ]
    }
   ],
   "source": [
    "# def parse_and_reshape(x):\n",
    "#     # Remove unnecessary characters\n",
    "#     x = x.replace('[', '').replace(']', '').replace(',', '')\n",
    "#     # Split into individual numbers and convert to float\n",
    "#     numbers = [float(num) for num in x.split()]\n",
    "#     # Convert list to numpy array and reshape\n",
    "#     return np.array(numbers).reshape((1, 1937, 512))\n",
    "\n",
    "# # Apply the function to each element in 'feature_vector'\n",
    "# df['feature_vector'] = df['feature_vector'].apply(parse_and_reshape)\n",
    "\n",
    "# # Verify the dtype of the column\n",
    "# print(df['feature_vector'].dtype)\n",
    "\n",
    "# # Print the DataFrame to check the results\n",
    "# print(df)\n",
    "\n",
    "# # Print the DataFrame to check the results\n",
    "# for row in df[\"feature_vector\"]:\n",
    "#     print(type(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7069c5a8-8a08-4417-9a37-3e52bcdde237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# df['feature_vector'] = df['feature_vector'].apply(np.array)\n",
    "\n",
    "# # Alternatively, use np.asarray() for the same effect\n",
    "# # df['feature_vector'] = df['feature_vector'].apply(np.asarray)\n",
    "# # Verify the dtype of the column\n",
    "# print(df['feature_vector'].dtype)\n",
    "\n",
    "# # Print the DataFrame to check the results\n",
    "# for row in df[\"feature_vector\"]:\n",
    "#     print(type(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581924da-ea05-46ba-83b0-4eaea731bf80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f3e3f68-67dc-4a7b-a455-559c2a80b307",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Incorrect padding",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m----> 5\u001b[0m     row \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(base64\u001b[38;5;241m.\u001b[39mbinascii\u001b[38;5;241m.\u001b[39ma2b_base64(row\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[1;31mError\u001b[0m: Incorrect padding"
     ]
    }
   ],
   "source": [
    "# import base64\n",
    "# import numpy as np\n",
    "\n",
    "# for row in x:\n",
    "#     row = np.frombuffer(base64.binascii.a2b_base64(row.encode(\"ascii\"))) \n",
    "    \n",
    "# # WOAH, GOTTA FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bd105e54-b2ef-48a7-89b3-aa3430e3f8dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[84], line 1\u001b[0m\n    x = x.apply(lambda x: np.array(eval(x)))\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m in \u001b[0;35mapply\u001b[0m\n    ).apply()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m in \u001b[0;35mapply\u001b[0m\n    return self.apply_standard()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m in \u001b[0;35mapply_standard\u001b[0m\n    mapped = obj._map_values(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m in \u001b[0;35m_map_values\u001b[0m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m in \u001b[0;35mmap_array\u001b[0m\n    return lib.map_infer(values, mapper, convert=convert)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mlib.pyx:2926\u001b[0m in \u001b[0;35mpandas._libs.lib.map_infer\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[84], line 1\u001b[1;36m in \u001b[1;35m<lambda>\u001b[1;36m\n\u001b[1;33m    x = x.apply(lambda x: np.array(eval(x)))\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [[[ 0.69247377  0.22540164 -1.4681103  ... -0.45674324 -1.0981839\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# x = x.apply(lambda x: np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67e829df-3a5e-4509-83ca-98752b3ce9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# for row in x:\n",
    "#     print(type(row))\n",
    "\n",
    "# # WOAH, GOTTA FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aab7f45-0862-4d07-a795-9f52feede839",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c54912a-6b06-44b6-b7ad-d89ab4085aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_tensors \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(row, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Verify each element is a tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_tensors):\n",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_tensors \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(row, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Verify each element is a tensor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_tensors):\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "# x_tensors = [torch.tensor(row, dtype=torch.float32) for row in x]\n",
    "\n",
    "# # Verify each element is a tensor\n",
    "# for i, tensor in enumerate(y_tensors):\n",
    "#     print(f\"Row {i}: {tensor}, Type: {type(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec053496-60c1-4037-ae31-241300f2419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6840a9b-9197-4ffa-a322-aef65e92c268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c891582a-85ee-40e8-a333-0b4660f99ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"Content\" , \"Pronun\" , \"Fluency\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "338ceb65-beb2-4cf7-bd07-3d69a0379180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Pronun</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Content  Pronun  Fluency\n",
       "0       18      11       25\n",
       "1       70      53       64\n",
       "2       54      40       51\n",
       "3       28      14       36\n",
       "4       16      11       25\n",
       "5       48      37       34\n",
       "6       52      35       53\n",
       "7       78      62       74\n",
       "8       90      73       81\n",
       "9       90      77       74"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3520d92a-cdd5-4484-938d-86b58a592d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f87edd70-1d19-4a5b-8df4-cf58dacd2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 11, 25],\n",
       "       [70, 53, 64],\n",
       "       [54, 40, 51],\n",
       "       [28, 14, 36],\n",
       "       [16, 11, 25],\n",
       "       [48, 37, 34],\n",
       "       [52, 35, 53],\n",
       "       [78, 62, 74],\n",
       "       [90, 73, 81],\n",
       "       [90, 77, 74]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c93344c2-ccab-4085-8149-e4d35e986236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: tensor([18., 11., 25.]), Type: <class 'torch.Tensor'>\n",
      "Row 1: tensor([70., 53., 64.]), Type: <class 'torch.Tensor'>\n",
      "Row 2: tensor([54., 40., 51.]), Type: <class 'torch.Tensor'>\n",
      "Row 3: tensor([28., 14., 36.]), Type: <class 'torch.Tensor'>\n",
      "Row 4: tensor([16., 11., 25.]), Type: <class 'torch.Tensor'>\n",
      "Row 5: tensor([48., 37., 34.]), Type: <class 'torch.Tensor'>\n",
      "Row 6: tensor([52., 35., 53.]), Type: <class 'torch.Tensor'>\n",
      "Row 7: tensor([78., 62., 74.]), Type: <class 'torch.Tensor'>\n",
      "Row 8: tensor([90., 73., 81.]), Type: <class 'torch.Tensor'>\n",
      "Row 9: tensor([90., 77., 74.]), Type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y_tensors = [torch.tensor(row, dtype=torch.float32) for row in y_np]\n",
    "\n",
    "# Verify each element is a tensor\n",
    "for i, tensor in enumerate(y_tensors):\n",
    "    print(f\"Row {i}: {tensor}, Type: {type(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86f9c9dc-3ae2-4b3c-94da-1a5ef8fc9f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([18., 11., 25.]),\n",
       " tensor([70., 53., 64.]),\n",
       " tensor([54., 40., 51.]),\n",
       " tensor([28., 14., 36.]),\n",
       " tensor([16., 11., 25.]),\n",
       " tensor([48., 37., 34.]),\n",
       " tensor([52., 35., 53.]),\n",
       " tensor([78., 62., 74.]),\n",
       " tensor([90., 73., 81.]),\n",
       " tensor([90., 77., 74.])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ae6240-2fa0-4ba5-8ef1-eca2fcbef2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26b4851c-5def-4224-8fcc-d3c46e1833bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tensor([[[ 0.6925,  0.2254, -1.4681,  ..., -0....\n",
      "1    tensor([[[ 0.6803,  0.1176, -1.7359,  ..., -0....\n",
      "2    tensor([[[ 0.6912,  0.2864, -1.4658,  ..., -0....\n",
      "3    tensor([[[ 0.7109,  0.2551, -1.6066,  ..., -0....\n",
      "4    tensor([[[ 0.6914,  0.3067, -1.4695,  ..., -0....\n",
      "5    tensor([[[ 0.6912,  0.2946, -1.4668,  ..., -0....\n",
      "6    tensor([[[ 0.6917,  0.3119, -1.4716,  ..., -0....\n",
      "7    tensor([[[ 0.6913,  0.3034, -1.4686,  ..., -0....\n",
      "8    tensor([[[ 0.6921,  0.2419, -1.4662,  ..., -0....\n",
      "9    tensor([[[ 0.6915,  0.3076, -1.4698,  ..., -0....\n",
      "Name: feature_vector, dtype: object\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a85f2f2-f524-4b6e-b3ec-b96f740949f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([18., 11., 25.]), tensor([70., 53., 64.]), tensor([54., 40., 51.]), tensor([28., 14., 36.]), tensor([16., 11., 25.]), tensor([48., 37., 34.]), tensor([52., 35., 53.]), tensor([78., 62., 74.]), tensor([90., 73., 81.]), tensor([90., 77., 74.])]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece765f1-dbbf-4080-9c47-cdcbba92d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "wav2vec2_model = Wav2Vec2Model.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b3360-dcf7-405a-a70d-990d95103881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): Wav2Vec2FeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "      (conv): ParametrizedConv1d(\n",
       "        1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _WeightNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (padding): Wav2Vec2SamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2475d1f0-bffa-4305-bb7f-bf3b321d1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_activation(x):\n",
    "    return 10 * tf.nn.sigmoid(x)\n",
    "    \n",
    "class Wav2Vec2ForScoring(tf.keras.Model):\n",
    "    def __init__(self , wav2vec2_model , num_classes):\n",
    "        super().__init__()\n",
    "        self.wav2vec2_model = wav2vec2_model\n",
    "        self.fc = tf.keras.layers.Dense(num_classes , activation = custom_activation)\n",
    "    \n",
    "    def call(self , inputs):\n",
    "        # pass the inputs to the bert model\n",
    "        x = self.wav2vec3_model(inputs)\n",
    "        # the model outputs: last_hidden state and pooler_output\n",
    "        # these are the logits with respect to bert\n",
    "        x = x[1]\n",
    "        # since we only wanted the pooler_output\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7468a24a-dd9f-4228-900d-1a7ce90dca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_model = Wav2Vec2ForScoring(wav2vec2_model , num_classes = 3)\n",
    "\n",
    "scoring_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8e894b-574a-400e-a435-c8c2973515ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Wav2Vec2ForScoring name=wav2_vec2_for_scoring_1, built=False>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73de65c2-99f9-4b10-97af-c726c694a089",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m scoring_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     (x , y),\n\u001b[0;32m      3\u001b[0m     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n"
     ]
    }
   ],
   "source": [
    "history = scoring_model.fit(\n",
    "    (x , y),\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7443c-a35e-48eb-9964-9c4d7653b851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
